{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66044b4-37d7-4560-bacc-aa5717bf5c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplot_results_plotter.matplot_results_plotter' from '/home/workspace/matplot_results_plotter/matplot_results_plotter.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from main import TimeLoopExperimentController\n",
    "import architectures.architecture_strategy\n",
    "import architectures.architecture_constants\n",
    "from architecture_results.derived_metrics_evaluator import DerivedMetricsEvaluator\n",
    "import matplot_results_plotter.matplot_results_plotter\n",
    "from architectures.architecture_constants import Architecture, GPUMemoryScale, RackSize, PEsConfig, base_config, resnet_18_layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Sequence, Tuple, Optional\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "importlib.reload(architectures.architecture_strategy)\n",
    "importlib.reload(architectures.architecture_constants)\n",
    "importlib.reload(matplot_results_plotter.matplot_results_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49e5aed-a9ed-4aa7-8ad5-2d69550326d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_bar_chart(\n",
    "    x_labels: Sequence[str],\n",
    "    series_1: Sequence[float],\n",
    "    series_2: Sequence[float],\n",
    "    series_labels: Tuple[str, str] = (\"Series 1\", \"Series 2\"),\n",
    "    colors: Tuple[str, str] = (\"tab:red\", \"tab:green\"),\n",
    "    chart_title: str = \"\",\n",
    "    y_axis_title: str = \"\",\n",
    "    use_scientific: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw a grouped‑bar chart with two bars per category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_labels : list[str]\n",
    "        Category names shown on the x‑axis (length N).\n",
    "    series_1, series_2 : list[float]\n",
    "        Heights for the two series (each of length N, same order as x_labels).\n",
    "    series_labels : (str, str), optional\n",
    "        Legend labels for the two series.\n",
    "    colors : (str, str), optional\n",
    "        Matplotlib color specs for the bars.\n",
    "    chart_title : str, optional\n",
    "        Title displayed above the chart.\n",
    "    y_axis_title : str, optional\n",
    "        Label for the y‑axis.\n",
    "    use_scientific : bool, optional\n",
    "        • True  → show axis in scientific notation (e.g. 1 e6)  \n",
    "        • False → show full integers (e.g. 1000000) with no commas\n",
    "    \"\"\"\n",
    "    if len(series_1) != len(series_2) or len(series_1) != len(x_labels):\n",
    "        raise ValueError(\"x_labels, series_1, and series_2 must all be the same length.\")\n",
    "    if len(series_1) == 0:\n",
    "        raise ValueError(\"Provide at least one category.\")\n",
    "\n",
    "    n = len(x_labels)\n",
    "    bar_width = 0.35\n",
    "    x = range(n)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Side‑by‑side bars ---------------------------------------------------------\n",
    "    ax.bar([p - bar_width / 2 for p in x], series_1,\n",
    "           width=bar_width, label=series_labels[0], color=colors[0])\n",
    "    ax.bar([p + bar_width / 2 for p in x], series_2,\n",
    "           width=bar_width, label=series_labels[1], color=colors[1])\n",
    "\n",
    "    # Axis & title formatting ---------------------------------------------------\n",
    "    ax.set_xticks(list(x))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(y_axis_title)\n",
    "    ax.set_title(chart_title)\n",
    "    ax.legend()\n",
    "\n",
    "    # --- control y‑axis number formatting -------------------------------------\n",
    "    if use_scientific:\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))  # 1 e6\n",
    "    else:\n",
    "        ax.ticklabel_format(axis='y', style='plain')                  # 1000000\n",
    "        fmt = ScalarFormatter(useOffset=False)\n",
    "        fmt.set_scientific(False)\n",
    "        ax.yaxis.set_major_formatter(fmt)\n",
    "\n",
    "    # Layout tweaks ------------------------------------------------------------\n",
    "    ax.margins(y=0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_three_bar_chart(x_labels, y_values, chart_title, y_axis_title):\n",
    "    \"\"\"\n",
    "    Draw a simple bar chart with three bars.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_labels : list[str]\n",
    "        The categorical labels shown on the x‑axis (length must be 3).\n",
    "    y_values : list[float] | tuple[float]\n",
    "        Heights of the three bars (same length as x_labels).\n",
    "    chart_title : str\n",
    "        Title displayed above the chart.\n",
    "    \"\"\"\n",
    "    if len(x_labels) != 3 or len(y_values) != 3:\n",
    "        raise ValueError(\"Provide exactly three x labels and three y values.\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bar_positions = range(3)    \n",
    "    ax.bar(bar_positions, y_values)\n",
    "\n",
    "    # Axis & title formatting\n",
    "    ax.set_xticks(bar_positions)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(y_axis_title)\n",
    "    ax.set_title(chart_title)\n",
    "\n",
    "    # Nice layout tweaks\n",
    "    ax.margins(y=0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f11cab-b782-41ca-89cb-b431c46ab3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#goal: find latency that match, compare the memories -> result should be that TP uses much less memory to achieve a similar latency. \n",
    "all_dp_star_latencies = {}\n",
    "all_tp_star_latencies = {}\n",
    "all_dp_ring_latencies = {}\n",
    "all_tp_ring_latencies = {}\n",
    "\n",
    "\n",
    "for memory in GPUMemoryScale:\n",
    "    for rack_size in RackSize:\n",
    "        for pe_config in PEsConfig:\n",
    "           \n",
    "            dp_estimator = DerivedMetricsEvaluator(Architecture.Data_Parallel, memory, rack_size, pe_config,'persisted_results/results_May 03, 2025 04:16:57 PM EST')\n",
    "            dp_config_str = f\"{Architecture.Data_Parallel.name}, {gpu_architecture.name}, {num_gpus.name}, {pe_config.name}\"\n",
    "            tp_estimator = DerivedMetricsEvaluator(Architecture.Tensor_Parallel, memory, rack_size, pe_config,'persisted_results/results_May 03, 2025 04:16:57 PM EST')\n",
    "            tp_config_str = f\"{Architecture.Tensor_Parallel.name}, {gpu_architecture.name}, {num_gpus.name}, {pe_config.name}\"\n",
    "            \n",
    "            all_dp_star_latencies[dp_config_str] = dp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "            all_tp_star_latencies[tp_config_str] = tp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "            all_dp_ring_latencies[dp_config_str] = dp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "            all_tp_ring_latencies[tp_config_str] = tp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49ffdcb1-7874-41d8-ad01-ea51436a2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_4MB, RACK_1, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_4MB, RACK_1, PE_1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.../Data_Parallel, MEMORY_4MB, RACK_1, PE_1/Layer Results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m tp_estimator \u001b[38;5;241m=\u001b[39m DerivedMetricsEvaluator(Architecture\u001b[38;5;241m.\u001b[39mTensor_Parallel, memory, rack_size, pe_config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m config_key \u001b[38;5;241m=\u001b[39m (rack_size\u001b[38;5;241m.\u001b[39mname, pe_config\u001b[38;5;241m.\u001b[39mname)  \u001b[38;5;66;03m# Use same rack & PE config to match\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m dp_star \u001b[38;5;241m=\u001b[39m \u001b[43mdp_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mderive_total_star_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottlenecked_latency\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m tp_star \u001b[38;5;241m=\u001b[39m tp_estimator\u001b[38;5;241m.\u001b[39mderive_total_star_results()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottlenecked_latency\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m dp_ring \u001b[38;5;241m=\u001b[39m dp_estimator\u001b[38;5;241m.\u001b[39mderive_total_ring_results()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottlenecked_latency\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/architecture_results/derived_metrics_evaluator.py:225\u001b[0m, in \u001b[0;36mDerivedMetricsEvaluator.derive_total_star_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mderive_total_star_results\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m#{'total_network_bytes': 0, 'total_onchip_bytes': 0}\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     total_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_total_data_movement()\n\u001b[1;32m    227\u001b[0m     avg_hops_per_comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    229\u001b[0m     total_sends \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/architecture_results/derived_metrics_evaluator.py:126\u001b[0m, in \u001b[0;36mDerivedMetricsEvaluator.get_total_data_movement\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m layer_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer Results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m returned \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_network_bytes\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_onchip_bytes\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m--> 126\u001b[0m folders \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#for TP, Base: each layer needs to be moved.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m folders_to_iterate \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.../Data_Parallel, MEMORY_4MB, RACK_1, PE_1/Layer Results'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Store latency and memory as tuples\n",
    "dp_star_latencies = defaultdict(list)\n",
    "tp_star_latencies = defaultdict(list)\n",
    "dp_ring_latencies = defaultdict(list)\n",
    "tp_ring_latencies = defaultdict(list)\n",
    "\n",
    "for memory in [GPUMemoryScale.RACK_8]:\n",
    "    for rack_size in RackSize:\n",
    "        for pe_config in PEsConfig:\n",
    "            # try:\n",
    "                dp_estimator = DerivedMetricsEvaluator(Architecture.Data_Parallel, memory, rack_size, pe_config, '...')\n",
    "                tp_estimator = DerivedMetricsEvaluator(Architecture.Tensor_Parallel, memory, rack_size, pe_config, '...')\n",
    "                \n",
    "                config_key = (rack_size.name, pe_config.name)  # Use same rack & PE config to match\n",
    "                \n",
    "                dp_star = dp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "                tp_star = tp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "                dp_ring = dp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "                tp_ring = tp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "    \n",
    "                dp_star_latencies[config_key].append((dp_star, memory))\n",
    "                tp_star_latencies[config_key].append((tp_star, memory))\n",
    "                dp_ring_latencies[config_key].append((dp_ring, memory))\n",
    "                tp_ring_latencies[config_key].append((tp_ring, memory))\n",
    "            # except:\n",
    "                # continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb30b663-f25a-4baa-b5fd-37d221f26cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "defaultdict(<class 'list'>, {})\n",
      "defaultdict(<class 'list'>, {})\n",
      "defaultdict(<class 'list'>, {})\n",
      "\n",
      "--- Matching Latencies (within ±100%) ---\n",
      "\n",
      "--- Matching Latencies (within ±100%) ---\n"
     ]
    }
   ],
   "source": [
    "print(dp_star_latencies)\n",
    "print(tp_star_latencies)\n",
    "print(dp_ring_latencies)\n",
    "print(tp_ring_latencies)\n",
    "\n",
    "def compare_latencies(dp_dict, tp_dict, threshold=1):\n",
    "    print(\"\\n--- Matching Latencies (within ±{}%) ---\".format(threshold * 100))\n",
    "    for config_key in dp_dict:\n",
    "        dp_results = dp_dict[config_key]\n",
    "        tp_results = tp_dict.get(config_key, [])\n",
    "        \n",
    "        for dp_latency, dp_memory in dp_results:\n",
    "            for tp_latency, tp_memory in tp_results:\n",
    "                if abs(dp_latency - tp_latency) / dp_latency <= threshold:\n",
    "                    print(f\"Config: {config_key}\")\n",
    "                    print(f\"  DP - Latency: {dp_latency:.2f}, Memory: {dp_memory}\")\n",
    "                    print(f\"  TP - Latency: {tp_latency:.2f}, Memory: {tp_memory}\")\n",
    "                    if tp_memory < dp_memory:\n",
    "                        print(\"  ✅ TP uses LESS memory for similar latency.\\n\")\n",
    "                    else:\n",
    "                        print(\"  ⚠️  TP uses MORE or EQUAL memory.\\n\")\n",
    "\n",
    "compare_latencies(dp_star_latencies, tp_star_latencies)\n",
    "compare_latencies(dp_ring_latencies, tp_ring_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01558b3a-f91e-4192-b5b1-27ca28856efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
