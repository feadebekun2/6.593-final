{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66044b4-37d7-4560-bacc-aa5717bf5c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplot_results_plotter.matplot_results_plotter' from '/home/workspace/matplot_results_plotter/matplot_results_plotter.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from main import TimeLoopExperimentController\n",
    "import architectures.architecture_strategy\n",
    "import architectures.architecture_constants\n",
    "from architecture_results.derived_metrics_evaluator import DerivedMetricsEvaluator\n",
    "import matplot_results_plotter.matplot_results_plotter\n",
    "from architectures.architecture_constants import Architecture, GPUMemoryScale, RackSize, PEsConfig, base_config, resnet_18_layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Sequence, Tuple, Optional\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "importlib.reload(architectures.architecture_strategy)\n",
    "importlib.reload(architectures.architecture_constants)\n",
    "importlib.reload(matplot_results_plotter.matplot_results_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49e5aed-a9ed-4aa7-8ad5-2d69550326d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_bar_chart(\n",
    "    x_labels: Sequence[str],\n",
    "    series_1: Sequence[float],\n",
    "    series_2: Sequence[float],\n",
    "    series_labels: Tuple[str, str] = (\"Series 1\", \"Series 2\"),\n",
    "    colors: Tuple[str, str] = (\"tab:red\", \"tab:green\"),\n",
    "    chart_title: str = \"\",\n",
    "    y_axis_title: str = \"\",\n",
    "    use_scientific: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw a grouped‑bar chart with two bars per category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_labels : list[str]\n",
    "        Category names shown on the x‑axis (length N).\n",
    "    series_1, series_2 : list[float]\n",
    "        Heights for the two series (each of length N, same order as x_labels).\n",
    "    series_labels : (str, str), optional\n",
    "        Legend labels for the two series.\n",
    "    colors : (str, str), optional\n",
    "        Matplotlib color specs for the bars.\n",
    "    chart_title : str, optional\n",
    "        Title displayed above the chart.\n",
    "    y_axis_title : str, optional\n",
    "        Label for the y‑axis.\n",
    "    use_scientific : bool, optional\n",
    "        • True  → show axis in scientific notation (e.g. 1 e6)  \n",
    "        • False → show full integers (e.g. 1000000) with no commas\n",
    "    \"\"\"\n",
    "    if len(series_1) != len(series_2) or len(series_1) != len(x_labels):\n",
    "        raise ValueError(\"x_labels, series_1, and series_2 must all be the same length.\")\n",
    "    if len(series_1) == 0:\n",
    "        raise ValueError(\"Provide at least one category.\")\n",
    "\n",
    "    n = len(x_labels)\n",
    "    bar_width = 0.35\n",
    "    x = range(n)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Side‑by‑side bars ---------------------------------------------------------\n",
    "    ax.bar([p - bar_width / 2 for p in x], series_1,\n",
    "           width=bar_width, label=series_labels[0], color=colors[0])\n",
    "    ax.bar([p + bar_width / 2 for p in x], series_2,\n",
    "           width=bar_width, label=series_labels[1], color=colors[1])\n",
    "\n",
    "    # Axis & title formatting ---------------------------------------------------\n",
    "    ax.set_xticks(list(x))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(y_axis_title)\n",
    "    ax.set_title(chart_title)\n",
    "    ax.legend()\n",
    "\n",
    "    # --- control y‑axis number formatting -------------------------------------\n",
    "    if use_scientific:\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))  # 1 e6\n",
    "    else:\n",
    "        ax.ticklabel_format(axis='y', style='plain')                  # 1000000\n",
    "        fmt = ScalarFormatter(useOffset=False)\n",
    "        fmt.set_scientific(False)\n",
    "        ax.yaxis.set_major_formatter(fmt)\n",
    "\n",
    "    # Layout tweaks ------------------------------------------------------------\n",
    "    ax.margins(y=0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_three_bar_chart(x_labels, y_values, chart_title, y_axis_title):\n",
    "    \"\"\"\n",
    "    Draw a simple bar chart with three bars.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_labels : list[str]\n",
    "        The categorical labels shown on the x‑axis (length must be 3).\n",
    "    y_values : list[float] | tuple[float]\n",
    "        Heights of the three bars (same length as x_labels).\n",
    "    chart_title : str\n",
    "        Title displayed above the chart.\n",
    "    \"\"\"\n",
    "    if len(x_labels) != 3 or len(y_values) != 3:\n",
    "        raise ValueError(\"Provide exactly three x labels and three y values.\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bar_positions = range(3)    \n",
    "    ax.bar(bar_positions, y_values)\n",
    "\n",
    "    # Axis & title formatting\n",
    "    ax.set_xticks(bar_positions)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(y_axis_title)\n",
    "    ax.set_title(chart_title)\n",
    "\n",
    "    # Nice layout tweaks\n",
    "    ax.margins(y=0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f11cab-b782-41ca-89cb-b431c46ab3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_4MB, RACK_1, PE_1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gpu_architecture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pe_config \u001b[38;5;129;01min\u001b[39;00m PEsConfig:\n\u001b[1;32m     12\u001b[0m     dp_estimator \u001b[38;5;241m=\u001b[39m DerivedMetricsEvaluator(Architecture\u001b[38;5;241m.\u001b[39mData_Parallel, memory, rack_size, pe_config,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersisted_results/results_May 03, 2025 04:16:57 PM EST\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     dp_config_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mArchitecture\u001b[38;5;241m.\u001b[39mData_Parallel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mgpu_architecture\u001b[49m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpe_config\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     tp_estimator \u001b[38;5;241m=\u001b[39m DerivedMetricsEvaluator(Architecture\u001b[38;5;241m.\u001b[39mTensor_Parallel, memory, rack_size, pe_config,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersisted_results/results_May 03, 2025 04:16:57 PM EST\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     tp_config_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mArchitecture\u001b[38;5;241m.\u001b[39mTensor_Parallel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu_architecture\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpe_config\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpu_architecture' is not defined"
     ]
    }
   ],
   "source": [
    "#goal: find latency that match, compare the memories -> result should be that TP uses much less memory to achieve a similar latency. \n",
    "all_dp_star_latencies = {}\n",
    "all_tp_star_latencies = {}\n",
    "all_dp_ring_latencies = {}\n",
    "all_tp_ring_latencies = {}\n",
    "\n",
    "\n",
    "for memory in GPUMemoryScale:\n",
    "    for rack_size in RackSize:\n",
    "        for pe_config in PEsConfig:\n",
    "           \n",
    "            dp_estimator = DerivedMetricsEvaluator(Architecture.Data_Parallel, memory, rack_size, pe_config,'persisted_results/results_May 03, 2025 04:16:57 PM EST')\n",
    "            dp_config_str = f\"{Architecture.Data_Parallel.name}, {gpu_architecture.name}, {num_gpus.name}, {pe_config.name}\"\n",
    "            tp_estimator = DerivedMetricsEvaluator(Architecture.Tensor_Parallel, memory, rack_size, pe_config,'persisted_results/results_May 03, 2025 04:16:57 PM EST')\n",
    "            tp_config_str = f\"{Architecture.Tensor_Parallel.name}, {gpu_architecture.name}, {num_gpus.name}, {pe_config.name}\"\n",
    "            \n",
    "            all_dp_star_latencies[dp_config_str] = dp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "            all_tp_star_latencies[tp_config_str] = tp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "            all_dp_ring_latencies[dp_config_str] = dp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "            all_tp_ring_latencies[tp_config_str] = tp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb21840-55b0-4388-b932-d8a92dbb82b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ffdcb1-7874-41d8-ad01-ea51436a2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_4, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_4, PE_1\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_4, PE_4\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_4, PE_4\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_4, PE_16\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_4, PE_16\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_8, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_8, PE_1\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_8, PE_4\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_8, PE_4\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_8, PE_16\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_8, PE_16\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_4, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_4, PE_1\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_4, PE_4\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_4, PE_4\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_4, PE_16\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_4, PE_16\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_8, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_8, PE_1\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_8, PE_4\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_8, PE_4\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_16MB, RACK_8, PE_16\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_16MB, RACK_8, PE_16\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_1024MB, RACK_4, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_1024MB, RACK_4, PE_1\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_1024MB, RACK_4, PE_4\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_1024MB, RACK_4, PE_4\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_1024MB, RACK_4, PE_16\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_1024MB, RACK_4, PE_16\n",
      "seeing num_gpus:  4\n",
      "seeing num_gpus:  4\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_1024MB, RACK_8, PE_1\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_1024MB, RACK_8, PE_1\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_1024MB, RACK_8, PE_4\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_1024MB, RACK_8, PE_4\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n",
      "DerivedMetricsEvaluator created for Data_Parallel, MEMORY_1024MB, RACK_8, PE_16\n",
      "DerivedMetricsEvaluator created for Tensor_Parallel, MEMORY_1024MB, RACK_8, PE_16\n",
      "seeing num_gpus:  8\n",
      "seeing num_gpus:  8\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Store latency and memory as tuples\n",
    "dp_star_latencies = defaultdict(list)\n",
    "tp_star_latencies = defaultdict(list)\n",
    "dp_ring_latencies = defaultdict(list)\n",
    "tp_ring_latencies = defaultdict(list)\n",
    "\n",
    "for memory in [GPUMemoryScale.MEMORY_16MB, GPUMemoryScale.MEMORY_16MB, GPUMemoryScale.MEMORY_1024MB]:\n",
    "    for rack_size in [RackSize.RACK_4, RackSize.RACK_8]:\n",
    "        for pe_config in PEsConfig:\n",
    "            # try:\n",
    "                dp_estimator = DerivedMetricsEvaluator(Architecture.Data_Parallel, memory, rack_size, pe_config, 'persisted_results/results_May 03, 2025 04:16:57 PM EST')\n",
    "                tp_estimator = DerivedMetricsEvaluator(Architecture.Tensor_Parallel, memory, rack_size, pe_config, 'persisted_results/results_May 03, 2025 04:16:57 PM EST')\n",
    "                \n",
    "                config_key = (rack_size.name, pe_config.name)  # Use same rack & PE config to match\n",
    "                \n",
    "                dp_star = dp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "                tp_star = tp_estimator.derive_total_star_results()['bottlenecked_latency']\n",
    "                dp_ring = dp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "                tp_ring = tp_estimator.derive_total_ring_results()['bottlenecked_latency']\n",
    "    \n",
    "                dp_star_latencies[config_key].append((dp_star, memory))\n",
    "                tp_star_latencies[config_key].append((tp_star, memory))\n",
    "                dp_ring_latencies[config_key].append((dp_ring, memory))\n",
    "                tp_ring_latencies[config_key].append((tp_ring, memory))\n",
    "            # except:\n",
    "            #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb30b663-f25a-4baa-b5fd-37d221f26cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------STAR-------\n",
      "\n",
      "--- Matching Latencies (within ±50.0%) ---\n",
      "Config                   DP Lat     DP Mem (MB)     TP Lat     TP Mem (MB) TP Better?\n",
      "--------------------------------------------------------------------------------\n",
      "('RACK_4', 'PE_1')     13911.20 ms          1024.0   13911.20 ms            16.0          ✅\n",
      "('RACK_4', 'PE_1')     13911.20 ms          1024.0   13911.20 ms            16.0          ✅\n",
      "('RACK_4', 'PE_4')      3949.85 ms          1024.0    3949.85 ms            16.0          ✅\n",
      "('RACK_4', 'PE_4')      3949.85 ms          1024.0    3949.85 ms            16.0          ✅\n",
      "('RACK_4', 'PE_16')      908.79 ms          1024.0    1223.49 ms            16.0          ✅\n",
      "('RACK_4', 'PE_16')      908.79 ms          1024.0    1223.49 ms            16.0          ✅\n",
      "('RACK_8', 'PE_1')      6955.60 ms          1024.0    6955.60 ms            16.0          ✅\n",
      "('RACK_8', 'PE_1')      6955.60 ms          1024.0    6955.60 ms            16.0          ✅\n",
      "('RACK_8', 'PE_4')      1974.93 ms          1024.0    1974.93 ms            16.0          ✅\n",
      "('RACK_8', 'PE_4')      1974.93 ms          1024.0    1974.93 ms            16.0          ✅\n",
      "('RACK_8', 'PE_16')      454.39 ms          1024.0     611.75 ms            16.0          ✅\n",
      "('RACK_8', 'PE_16')      454.39 ms          1024.0     611.75 ms            16.0          ✅\n",
      "\n",
      "Summary:\n",
      "- Total matching configurations: 54\n",
      "- TP used less memory in 12 cases (22.2%)\n",
      "-------RING-------\n",
      "\n",
      "--- Matching Latencies (within ±50.0%) ---\n",
      "Config                   DP Lat     DP Mem (MB)     TP Lat     TP Mem (MB) TP Better?\n",
      "--------------------------------------------------------------------------------\n",
      "('RACK_4', 'PE_1')     13911.20 ms          1024.0   13911.20 ms            16.0          ✅\n",
      "('RACK_4', 'PE_1')     13911.20 ms          1024.0   13911.20 ms            16.0          ✅\n",
      "('RACK_4', 'PE_4')      3949.85 ms          1024.0    3949.85 ms            16.0          ✅\n",
      "('RACK_4', 'PE_4')      3949.85 ms          1024.0    3949.85 ms            16.0          ✅\n",
      "('RACK_4', 'PE_16')      908.79 ms          1024.0    1223.49 ms            16.0          ✅\n",
      "('RACK_4', 'PE_16')      908.79 ms          1024.0    1223.49 ms            16.0          ✅\n",
      "('RACK_8', 'PE_1')      6955.60 ms          1024.0    6955.60 ms            16.0          ✅\n",
      "('RACK_8', 'PE_1')      6955.60 ms          1024.0    6955.60 ms            16.0          ✅\n",
      "('RACK_8', 'PE_4')      1974.93 ms          1024.0    1974.93 ms            16.0          ✅\n",
      "('RACK_8', 'PE_4')      1974.93 ms          1024.0    1974.93 ms            16.0          ✅\n",
      "('RACK_8', 'PE_16')      454.39 ms          1024.0     611.75 ms            16.0          ✅\n",
      "('RACK_8', 'PE_16')      454.39 ms          1024.0     611.75 ms            16.0          ✅\n",
      "\n",
      "Summary:\n",
      "- Total matching configurations: 54\n",
      "- TP used less memory in 12 cases (22.2%)\n"
     ]
    }
   ],
   "source": [
    "# print(dp_star_latencies)\n",
    "# print(tp_star_latencies)\n",
    "# print(dp_ring_latencies)\n",
    "# print(tp_ring_latencies)\n",
    "\n",
    "def latency_in_cyles_to_ms(x):\n",
    "\n",
    "    return x/1000000\n",
    "    \n",
    "def compare_latencies(dp_dict, tp_dict, threshold=0.5):\n",
    "    match_count = 0\n",
    "    tp_better_count = 0\n",
    "\n",
    "    print(\"\\n--- Matching Latencies (within ±{}%) ---\".format(threshold * 100))\n",
    "    print(\"{:<20} {:>10} {:>15} {:>10} {:>15} {:>10}\".format(\n",
    "        \"Config\", \"DP Lat\", \"DP Mem (MB)\", \"TP Lat\", \"TP Mem (MB)\", \"TP Better?\"\n",
    "    ))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for config_key in dp_dict:\n",
    "        dp_results = dp_dict[config_key]\n",
    "        tp_results = tp_dict.get(config_key, [])\n",
    "        \n",
    "        for dp_latency, dp_memory in dp_results:\n",
    "            for tp_latency, tp_memory in tp_results:\n",
    "                if abs(dp_latency - tp_latency) / dp_latency <= threshold:\n",
    "                    match_count += 1\n",
    "                    tp_better = tp_memory.size_in_mb < dp_memory.size_in_mb\n",
    "                    if tp_better:\n",
    "                        tp_better_count += 1\n",
    "\n",
    "                        print(\"{:<20} {:>10.2f} ms {:>15.1f} {:>10.2f} ms {:>15.1f} {:>10}\".format(\n",
    "                            str(config_key),\n",
    "                            latency_in_cyles_to_ms(dp_latency),\n",
    "                            dp_memory.size_in_mb,\n",
    "                            latency_in_cyles_to_ms(tp_latency),\n",
    "                            tp_memory.size_in_mb,\n",
    "                            \"✅\" if tp_better else \"❌\"\n",
    "                        ))\n",
    "\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"- Total matching configurations: {match_count}\")\n",
    "    print(f\"- TP used less memory in {tp_better_count} cases ({(tp_better_count / match_count * 100 if match_count else 0):.1f}%)\")\n",
    "\n",
    "\n",
    "print(\"-------STAR-------\")\n",
    "compare_latencies(dp_star_latencies, tp_star_latencies)\n",
    "print(\"-------RING-------\")\n",
    "compare_latencies(dp_ring_latencies, tp_ring_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01558b3a-f91e-4192-b5b1-27ca28856efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236bbdc-6192-412b-ba8d-091ec90bed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
